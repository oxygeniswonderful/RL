{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "hPgO2i8IYWHO"
      },
      "source": [
        "# Глубокий кросс-энтропийный метод\n",
        "\n",
        "#### дедлайн задания: 19 марта, 23:59 GMT+3\n",
        "\n",
        "В данной работе будет рассмотрено обобщение кросс-энтропийного метода на случай параметризации агента с помощью нейросети. Перед вами будет поставлена задача обучить многослойную нейронную сеть для решения простых игр в непрерывных пространствах состояний."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VfFjCzcYWHQ"
      },
      "source": [
        "# Работа выполнена: Восканян Давид Тигранович, М05-212б"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMsVzQs-YWHR",
        "outputId": "2b640bd2-c3b1-4494-d713-4a55867b1fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package libav-tools is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  ffmpeg\n",
            "\n",
            "E: Package 'libav-tools' has no installation candidate\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting piglet\n",
            "  Downloading piglet-1.0.0-py2.py3-none-any.whl (2.2 kB)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Collecting gym[all]==0.18.3\n",
            "  Downloading gym-0.18.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from gym[all]==0.18.3) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.9/dist-packages (from gym[all]==0.18.3) (1.22.4)\n",
            "Collecting pyglet<=1.5.15,>=1.4.0\n",
            "  Downloading pyglet-1.5.15-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<=8.2.0\n",
            "  Downloading Pillow-8.2.0-cp39-cp39-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting mujoco_py<2.0,>=1.50\n",
            "  Downloading mujoco-py-1.50.1.68.tar.gz (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python>=3. in /usr/local/lib/python3.9/dist-packages (from gym[all]==0.18.3) (4.7.0.72)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (from gym[all]==0.18.3) (2.25.1)\n",
            "Collecting atari_py~=0.2.0\n",
            "  Downloading atari_py-0.2.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting piglet-templates\n",
            "  Downloading piglet_templates-1.3.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from atari_py~=0.2.0->gym[all]==0.18.3) (1.16.0)\n",
            "Collecting glfw>=1.4.0\n",
            "  Downloading glfw-2.5.7-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.7/207.7 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.9/dist-packages (from mujoco_py<2.0,>=1.50->gym[all]==0.18.3) (0.29.33)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.9/dist-packages (from mujoco_py<2.0,>=1.50->gym[all]==0.18.3) (1.15.1)\n",
            "Collecting lockfile>=0.12.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting imageio\n",
            "  Downloading imageio-2.26.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.26.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.24.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.23.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.4-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.5-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.18.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.17.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.16.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.14.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.14.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.12.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.11.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.11.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from piglet-templates->piglet) (2.1.2)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.9/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from piglet-templates->piglet) (3.0.9)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from piglet-templates->piglet) (22.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.10->mujoco_py<2.0,>=1.50->gym[all]==0.18.3) (2.21)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse->piglet-templates->piglet) (0.40.0)\n",
            "Building wheels for collected packages: box2d-py, mujoco_py, gym\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for mujoco_py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mujoco_py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for mujoco_py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gym\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gym\n",
            "Failed to build box2d-py mujoco_py gym\n",
            "Installing collected packages: pyvirtualdisplay, pyglet, lockfile, glfw, box2d-py, Pillow, cloudpickle, atari_py, piglet-templates, imageio, gym, piglet, mujoco_py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for box2d-py\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for box2d-py ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m box2d-py\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
          ]
        }
      ],
      "source": [
        "# Для корректной работы ноутбука может понадобиться исполнение следующих команд\n",
        "# (инструкция для Unix-подобных систем):\n",
        "!apt-get install -y xvfb x11-utils ffmpeg libav-tools python-opengl\n",
        "!pip install piglet pyvirtualdisplay gym[all]==0.18.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:08.272254Z",
          "start_time": "2019-09-18T14:49:08.268020Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTXoqsdZYWHR",
        "outputId": "869e9595-eb31-4702-8922-b356f44e8dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 18:19:04--  https://bit.ly/2FMJP5K\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring19/setup_colab.sh [following]\n",
            "--2023-03-21 18:19:05--  https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring19/setup_colab.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262 [text/plain]\n",
            "Saving to: ‘setup.py’\n",
            "\n",
            "\rsetup.py              0%[                    ]       0  --.-KB/s               \rsetup.py            100%[===================>]     262  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-21 18:19:05 (9.54 MB/s) - ‘setup.py’ saved [262/262]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 780 kB of archives.\n",
            "After this operation, 2,271 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.6 [780 kB]\n",
            "Fetched 780 kB in 1s (1,126 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 128276 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.20.13-1ubuntu1~20.04.6_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.6) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.6) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "--2023-03-21 18:19:18--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640 [text/plain]\n",
            "Saving to: ‘../xvfb’\n",
            "\n",
            "../xvfb             100%[===================>]     640  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-21 18:19:18 (28.5 MB/s) - ‘../xvfb’ saved [640/640]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libpython2-stdlib python2 python2-minimal\n",
            "Suggested packages:\n",
            "  python-tk python-numpy libgle3 python2-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libpython2-stdlib python-opengl python2 python2-minimal\n",
            "0 upgraded, 5 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 621 kB of archives.\n",
            "After this operation, 6,059 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n",
            "Fetched 621 kB in 1s (1,088 kB/s)\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 128283 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 128312 files and directories currently installed.)\n",
            "Preparing to unpack .../python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-2build1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-2build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyglet==1.2.4\n",
            "  Downloading pyglet-1.2.4-py3-none-any.whl (964 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m964.6/964.6 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.15\n",
            "    Uninstalling pyglet-1.5.15:\n",
            "      Successfully uninstalled pyglet-1.5.15\n",
            "Successfully installed pyglet-1.2.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym[classic_control]==0.18.3\n",
            "  Using cached gym-0.18.3.tar.gz (1.6 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]==0.18.3) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]==0.18.3) (1.22.4)\n",
            "Collecting pyglet<=1.5.15,>=1.4.0\n",
            "  Using cached pyglet-1.5.15-py3-none-any.whl (1.1 MB)\n",
            "Collecting Pillow<=8.2.0\n",
            "  Using cached Pillow-8.2.0-cp39-cp39-manylinux1_x86_64.whl (3.0 MB)\n",
            "Collecting cloudpickle<1.7.0,>=1.2.0\n",
            "  Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: gym\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gym\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gym\n",
            "Failed to build gym\n",
            "Installing collected packages: pyglet, Pillow, cloudpickle, gym\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.2.4\n",
            "    Uninstalling pyglet-1.2.4:\n",
            "      Successfully uninstalled pyglet-1.2.4\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py install for gym ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: gym was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.25.1 requires pillow>=8.3.2, but you have pillow 8.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-8.2.0 cloudpickle-1.6.0 gym-0.18.3 pyglet-1.5.15\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ],
      "source": [
        "# В Google Colab раскомментируйте это:\n",
        "!wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
        "!pip install --upgrade gym[classic_control]==0.18.3\n",
        "# XVFB будет запущен в случае исполнения на сервере\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:15.992701Z",
          "start_time": "2019-09-18T14:49:08.275069Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Hr1-hpETYWHS",
        "outputId": "a06bec29-6043-4288-98e9-a9a40683d6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "размерность вектора состояний dim = 4\n",
            "n_actions = 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=1.)\n",
        "\n",
        "# если есть вывод \"<classname> has no attribute .env\", удалите .env или обновите gym\n",
        "env = gym.make(\"CartPole-v1\").env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "print(\"размерность вектора состояний dim =\", state_dim)\n",
        "print(\"n_actions =\", n_actions)\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:15.999558Z",
          "start_time": "2019-09-18T14:49:15.995465Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKvCrkI-YWHS",
        "outputId": "aa94ccbd-6a22-4bd8-ff12-5d1851d9597c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32),\n",
              " Discrete(2))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "ANz6ltalYWHT"
      },
      "source": [
        "# Нейросетевая политика, основная задача (10 баллов)\n",
        "\n",
        "Для текущей задачи будет использована упрощённая нейронная сеть, реализованная в библиотеке __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Что для решения задачи понадобится:\n",
        "\n",
        "* `agent.partial_fit(states, actions)` - выполнение одного прохода (одной эпохи) по данным для настройки параметров. В ходе вызова данного метода происходит приближённая максимизация вероятности :actions: при условии :states:\n",
        "* `agent.predict_proba(states)` - оценка вероятностей всех действий, матрица формы __[len(states), n_actions]__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:18.770363Z",
          "start_time": "2019-09-18T14:49:16.001843Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "U5rW3U8ZYWHT",
        "outputId": "092fa77b-75c7-4264-e272-23a3d2a3cfe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', hidden_layer_sizes=(20, 20))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(20, 20))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(20, 20))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "\n",
        "agent = MLPClassifier(\n",
        "    hidden_layer_sizes=(20, 20),\n",
        "    activation='tanh',\n",
        ")\n",
        "\n",
        "# инициализация агента на размерности пространства состояний и пространства действий\n",
        "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:18.800907Z",
          "start_time": "2019-09-18T14:49:18.772874Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "tw3IAIfEYWHT"
      },
      "outputs": [],
      "source": [
        "def generate_session(agent, t_max=1000, test=False):\n",
        "    \"\"\"\n",
        "    Сыграть отдельный эпизод, используя нейросетевую параметризацию агента.\n",
        "    Останов после :t_max: шагов среды.\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        \n",
        "        # Используйте модель агента для оценки распределения на действия для текущего состояния :s:\n",
        "        probs = agent.predict_proba(s.reshape(1, -1)).reshape(-1)\n",
        "        assert probs.shape == (n_actions,), \"Нужно получить вектор вероятностей (функция np.reshape в помощь)\"\n",
        "        \n",
        "        # Используйте текущую оценку политики для выбора действия\n",
        "        if test:\n",
        "            # на тестовом прогоне или на валидации используйте\n",
        "            # детерминированную стратегию\n",
        "            a = np.argmax(probs)\n",
        "            # ^-- подсказка: попробуйте функцию np.argmax\n",
        "        else:\n",
        "            # сэмплирование пропорционально политике $\\pi(a|s)$,\n",
        "            # не нужно выбирать детерминированно наиболее вероятное действие\n",
        "            a = np.random.choice(len(probs), p=probs)\n",
        "            # ^-- подсказка: попробуйте функцию np.random.choice\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        # Запись статистики текущего эпизода\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "    return states, actions, total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:18.825783Z",
          "start_time": "2019-09-18T14:49:18.804175Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvQg4MdJYWHU",
        "outputId": "1abadf94-b15a-4e05-e675-8f8aacb8afea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "states: [[ 0.0241524  -0.00616832  0.03759726 -0.00240827]\n",
            " [ 0.02402903  0.18839483  0.0375491  -0.28299575]\n",
            " [ 0.02779693  0.38296165  0.03188918 -0.56360342]\n",
            " [ 0.03545616  0.57762197  0.02061711 -0.84607162]\n",
            " [ 0.0470086   0.3822249   0.00369568 -0.5469773 ]]\n",
            "actions: [1, 1, 1, 0, 1]\n",
            "reward: 5.0\n"
          ]
        }
      ],
      "source": [
        "dummy_states, dummy_actions, dummy_reward = generate_session(agent, t_max=5)\n",
        "print(\"states:\", np.stack(dummy_states))\n",
        "print(\"actions:\", dummy_actions)\n",
        "print(\"reward:\", dummy_reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "pYsp8g2lYWHV"
      },
      "source": [
        "### Шаги кросс-энтропийного метода\n",
        "Общая схема кросс-энтропийного метода (CEM) приведена на странице 35 (параграф 2.2.4.) учебного [пособия](https://arxiv.org/pdf/2201.09746.pdf).\n",
        "\n",
        "Глубокий CEM использует точно такую же стратегию, что и обычный CEM.\n",
        "\n",
        "Главное отличие состоит в том, что теперь каждое наблюдение не число, а `float32` вектор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:18.845899Z",
          "start_time": "2019-09-18T14:49:18.827600Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "T7Z_ElfxYWHV"
      },
      "outputs": [],
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Выбрать states и actions из игр с rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, оба 1D lists of states и actions из наилучших эпизодов\n",
        "\n",
        "    Просьба сохранять порядок elite states и actions \n",
        "    [то есть сортированы по номерам эпизодов и в хронологическом порядке в каждом эпизоде]\n",
        "\n",
        "    Просьба не считать по умолчанию states как целочисленные значения\n",
        "    (они позже примут другой формат).\n",
        "    \"\"\"\n",
        "\n",
        "    top_rewards = np.percentile(rewards_batch, percentile)\n",
        "    elite_actions, elite_states = [], []\n",
        "\n",
        "    for session_i in range(len(states_batch)):\n",
        "      if rewards_batch[session_i] >= top_rewards:\n",
        "        elite_states.extend(states_batch[session_i])\n",
        "        elite_actions.extend(actions_batch[session_i])\n",
        "        \n",
        "    # Заметим, что это отличается от табличного случая.\n",
        "    # Теперь наша нейронная сеть обучается на одном объекте с входной размерностью `(1, n_states)`.\n",
        "    # То есть следует использовать `np.squeeze`, чтобы избавиться от ведущего измерения в `select_elites`.\n",
        "    \n",
        "    elite_states = np.squeeze(elite_states)\n",
        "    elite_actions = np.squeeze(elite_actions)\n",
        "    \n",
        "    return elite_states, elite_actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "oDkGMFvjYWHW"
      },
      "source": [
        "# Цикл обучения\n",
        "Генерация эпизодов, выбор N лучших и обучение на них."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T14:49:18.868655Z",
          "start_time": "2019-09-18T14:49:18.848299Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "U3BdYLBdYWHW"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    Функция-помощник, которая визуализирует процесс обучения.\n",
        "    Никакой крутой математики здесь нет, только построение графиков.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    print(\"средняя награда = %.3f, порог=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Средние награды')\n",
        "    plt.plot(list(zip(*log))[1], label='Пороги наград')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
        "               [0], [100], label=\"перцентиль\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    clear_output(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T15:04:30.103876Z",
          "start_time": "2019-09-18T14:49:18.873681Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "CAJApw9AYWHW",
        "outputId": "4cae07f9-03e9-4439-f725-f02bec319fb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вы выиграли! Можете прервать процедуру обучения с помощью сигнала KeyboardInterrupt.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Победа! Игра окончена на итерации 41!"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "sns.set(font_scale=1.)\n",
        "n_sessions = 100\n",
        "percentile = 70\n",
        "log = []\n",
        "\n",
        "for i in range(100):\n",
        "    print(\"Итерация метода № {}:\".format(i + 1))\n",
        "    # генерация новых эпизодов\n",
        "    sessions = [generate_session(agent) for i in range(n_sessions)]\n",
        "\n",
        "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
        "\n",
        "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
        "\n",
        "    agent.partial_fit(elite_states, elite_actions)\n",
        "\n",
        "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
        "\n",
        "    if np.mean(rewards_batch) > 190:\n",
        "        print(\"Вы выиграли! Можете прервать процедуру обучения с помощью сигнала KeyboardInterrupt.\")\n",
        "        raise KeyboardInterrupt(\"Победа! Игра окончена на итерации {}!\".format(i+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "zOWgG2yUYWHX"
      },
      "source": [
        "# Результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T15:04:43.484212Z",
          "start_time": "2019-09-18T15:04:30.106224Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "uArPHpNSYWHX"
      },
      "outputs": [],
      "source": [
        "# запись эпизодов\n",
        "import gym.wrappers\n",
        "for kind, directory in [(True, \"test\"), (False, \"sample\")]:\n",
        "    env = gym.wrappers.Monitor(gym.make(\"CartPole-v1\"),\n",
        "                               directory=\"videos/CartPole-v1/{}\".format(directory), force=True)\n",
        "    sessions = [generate_session(agent, test=kind) for _ in range(100)]\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5dPc6IfYWHX"
      },
      "source": [
        "Детерминированная политика:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T15:04:43.508057Z",
          "start_time": "2019-09-18T15:04:43.498495Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "colab": {
          "resources": {
            "http://localhost:8080/videos/CartPole-v1/test/openaigym.video.0.134.video000064.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "ZRtF7UUoYWHX",
        "outputId": "9e069a28-0360-47a5-b8da-a0302bc4b410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"./videos/CartPole-v1/test/openaigym.video.0.134.video000064.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# демонстрация видео\n",
        "from IPython.display import HTML\n",
        "import os\n",
        "\n",
        "video_names = list(\n",
        "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/CartPole-v1/test\")))\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(\"./videos/CartPole-v1/test/\"+video_names[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sES1sw3DYWHY"
      },
      "source": [
        "Стохастическая политика:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/videos/CartPole-v1/sample/openaigym.video.1.134.video000027.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "1uzLq2ivYWHZ",
        "outputId": "da392e6b-3f04-4def-dbde-5a94125183c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"./videos/CartPole-v1/sample/openaigym.video.1.134.video000027.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "video_names = list(\n",
        "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/CartPole-v1/sample\")))\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(\"./videos/CartPole-v1/sample/\"+video_names[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "kCdFSSaFYWHa"
      },
      "source": [
        "# Дополнительные задания\n",
        "\n",
        "#### дедлайн дополнительного задания: за две недели до официальной даты экзамена, 23:59 GMT+3\n",
        "\n",
        "### Глубокий кросс-энтропийный метод\n",
        "\n",
        "На данный момент у Вас должна быть достаточно хорошая награда в [CartPole-v1](https://www.gymlibrary.dev/environments/classic_control/cart_pole/), чтобы считать основное задание выполненным (см. ссылку). Время попробовать что-нибудь посложнее.\n",
        "\n",
        "### Задания (вплоть до 10 баллов)\n",
        "\n",
        "* __2.1__ Выбрать одну из сред: MountainCar-v0 или LunarLander-v2.\n",
        "  * Для MountainCar, получить среднее вознаграждение __как минимум -150__\n",
        "  * For LunarLander, получить среднее вознаграждение __как минимум +50__\n",
        "\n",
        "Рекомендуем обратить внимание на раздел с советами ниже, это важно.\n",
        "\n",
        "* __2.2__ Разработать способ ускорения обучения хотя бы в два раза по сравнению с версией по умолчанию\n",
        "  * Очевидное улучшение: использовать [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8) или multiprocessing\n",
        "  * Попробовать переиспользовать сэмплы из 3-5 последних итераций при вычислении порога и при обучении\n",
        "  * Поэкспериментировать с количеством итераций обучения и шагом метода обучения (learning rate) нейронной сети (смотеть params)\n",
        "  \n",
        "  \n",
        "### Советы\n",
        "* Страница Gym: [MountainCar](https://www.gymlibrary.dev/environments/classic_control/mountain_car/), [LunarLander](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)\n",
        "* Эпизоды в MountainCar могут длиться более 10k+ шагов. Убедитесь, что параметр ```t_max``` не меньше 10k.\n",
        " * Также может быть хорошей идеей строго отбирать награды через \">\", а не \">=\" (strictly_select_elites). Если 90% Ваших эпизодов имеют награду -10k и 20% лучше, тода если Вы используйте перцентиль 20% как порог, R >= порог __не может отклонить неуспешные эпизоды__, в то время как R > справляется с этим корректно.\n",
        "* _проблема сред gym_: некоторые версии gym ограничивают эпизод 200 шагами. Это ограничивает возможности CEM в обучении в большинстве случаев. Убедитесь, что Ваш агент способен симулировать эпизоды с заданным __t_max__, и если нет, то попробуйте `env = gym.make(\"MountainCar-v0\").env` или в ином случае избавьтесь от TimeLimit wrapper.\n",
        "* Если Вы пользуетесь старой _swig_ библиотекой для LunarLander-v2, у Вас может возникнуть ошибка. Детали по [ссылке](https://github.com/openai/gym/issues/100) с решением проблемы.\n",
        "* Если CEM не будет обучаться, то построение диаграмм распределения награды и запись видео эпизодов могут помочь: они Вас могут натолкнуть на идею исправления.\n",
        "* 20-нейронной сети может не хватить, не стесняйтесь экспериментировать.\n",
        "\n",
        "Ячейка с кодом ниже может оказаться полезной:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vNV17WUYWHa"
      },
      "outputs": [],
      "source": [
        "def visualize_mountain_car(env, agent):\n",
        "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
        "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
        "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
        "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
        "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og24RKWXYWHa"
      },
      "source": [
        "Функции-помощники для инициализации среды:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T12:21:17.631855Z",
          "start_time": "2019-09-18T12:21:17.626438Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "fJJKJ90NYWHa"
      },
      "outputs": [],
      "source": [
        "def get_env(name, classification=True):\n",
        "    env = gym.make(name).env\n",
        "    \n",
        "    env.reset()\n",
        "    if classification:\n",
        "        n_actions = env.action_space.n\n",
        "    else:\n",
        "        n_actions = sum(env.action_space.shape)\n",
        "    state_dim = env.observation_space.shape[0]\n",
        "    \n",
        "    plt.imshow(env.render(\"rgb_array\"))\n",
        "    print(\"state vector dim =\", state_dim)\n",
        "    print(\"n_actions =\", n_actions)\n",
        "    \n",
        "    env.close()\n",
        "    return env, n_actions, state_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MutcoATYWHb"
      },
      "source": [
        "Строгий отбор states и actions на основе перцентилей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T11:27:01.282729Z",
          "start_time": "2019-09-18T11:27:01.270077Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "NtErHSp7YWHb"
      },
      "outputs": [],
      "source": [
        "def strictly_select_elites(states_batch, actions_batch, rewards_batch, percentile=50, classification=True):\n",
        "    \"\"\"\n",
        "    Выбрать states и actions из игр с rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, оба 1D lists of states и actions из наилучших эпизодов\n",
        "\n",
        "    Просьба сохранять порядок elite states и actions \n",
        "    [то есть сортированы по номерам эпизодов и в хронологическом порядке в каждом эпизоде]\n",
        "\n",
        "    Просьба не считать по умолчанию states как целочисленные значения\n",
        "    (они позже примут другой формат).\n",
        "    Отбор в случае решения задачи классификации и в случае решения задачи регрессии несколько отличаются.\n",
        "    \"\"\"\n",
        "\n",
        "    < Ваша имплементация >\n",
        "    \n",
        "    return elite_states, elite_actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSy5n-HzYWHb"
      },
      "source": [
        "Обёртка для инициализации агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T15:07:35.917489Z",
          "start_time": "2019-09-18T15:07:35.909155Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "QXgQ3H7VYWHb"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "\n",
        "def init_agent(env, classification=True, **params):\n",
        "    if classification:\n",
        "        agent = MLPClassifier(\n",
        "            hidden_layer_sizes=(20, 20, 20, 20),\n",
        "            activation='tanh',\n",
        "        )\n",
        "    else:\n",
        "        agent = MLPRegressor(\n",
        "            hidden_layer_sizes=(20, 20, 20, 20),\n",
        "            activation='tanh',\n",
        "        )\n",
        "    \n",
        "    agent.set_params(**params)\n",
        "    \n",
        "    if classification:\n",
        "        n_actions = env.action_space.n\n",
        "        agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))\n",
        "    else:\n",
        "        n_actions = sum(env.action_space.shape)\n",
        "        if n_actions > 1:\n",
        "            agent.partial_fit([env.reset()], np.random.randn(1, n_actions))\n",
        "        else:\n",
        "            agent.partial_fit([env.reset()], np.random.randn(n_actions))\n",
        "    \n",
        "    return agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7gpmDDPYWHc"
      },
      "source": [
        "Генератор эпизодов, приспособленный к параллелизации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqS1dBDfYWHc"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "\n",
        "\n",
        "def generate_parallel_session(agent, name='MountainCar-v0', t_max=10000, classification=True,\n",
        "                              epsilon=0.01, agent_mul_fac=1.0, test=False, env=None):\n",
        "    \"\"\"\n",
        "    Сыграть отдельный эпизод, используя нейросетевую параметризацию агента.\n",
        "    Останов после :t_max: шагов среды.\n",
        "    \"\"\"\n",
        "    \n",
        "    states, actions = [], []\n",
        "    total_reward = 0\n",
        "    \n",
        "    if env is None:\n",
        "        env = gym.make(name).env\n",
        "    if classification:\n",
        "        n_actions = env.action_space.n\n",
        "    else:\n",
        "        n_actions = sum(env.action_space.shape)\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        \n",
        "        if classification:\n",
        "            probs = < оценка вероятностей нейросетевой модели >\n",
        "\n",
        "            assert probs.shape == (n_actions,), \"Нужно получить вектор вероятностей\" +\\\n",
        "                \"(функция np.reshape в помощь)\"\n",
        "            \n",
        "            if test:\n",
        "                a = < наиболее вероятное действия относительно probs >\n",
        "            else:\n",
        "                a = < сэмпл действия из распределения probs >\n",
        "        else:\n",
        "            expected_action = < оценка с помощью модели среднего действия, помноженного на agent_mul_fac >\n",
        "            \n",
        "            if test:\n",
        "                a = < само expected_action >\n",
        "            else:\n",
        "                a = < сэмпл из Normal(expected_action, epsilon) >\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "    \n",
        "    del env, s, new_s, a\n",
        "    \n",
        "    return states, actions, total_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1zzi4onYWHc"
      },
      "source": [
        "Функция для обучения агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T11:27:05.573082Z",
          "start_time": "2019-09-18T11:27:05.556702Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "ZIDRI1EFYWHc"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "def train_agent(classification=True, epsilon=0.01, name='MountainCar-v0', n_train_steps=100,\n",
        "                n_game_steps=10000, n_sessions=100, percentile=70, goal_score=-150, history_length=4,\n",
        "                n_jobs=16, verbose=True, agent_mul_fac=1.0, **params):\n",
        "    env = gym.make(name).env\n",
        "    if classification:\n",
        "        n_actions = env.action_space.n\n",
        "    else:\n",
        "        n_actions = sum(env.action_space.shape)\n",
        "    \n",
        "    agent = init_agent(env, classification, **params)\n",
        "    \n",
        "    if verbose:\n",
        "        print('Шаг агента = {}'.format(agent.learning_rate_init), flush=True)\n",
        "    \n",
        "    log = []\n",
        "    sessions = deque([], history_length * n_sessions)\n",
        "    \n",
        "    for i in range(n_train_steps):\n",
        "        if n_jobs > 1:\n",
        "            pool = Pool(processes=n_jobs, maxtasksperchild=10)\n",
        "            sessions.extend(pool.map(partial(generate_parallel_session, agent, name, n_game_steps,\n",
        "                                             classification, epsilon, agent_mul_fac), [False] * n_sessions))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "            del pool\n",
        "        else:\n",
        "            sessions.extend([generate_parallel_session(\n",
        "                agent, name, n_game_steps, classification, epsilon, agent_mul_fac,\n",
        "                False) for _ in range(n_sessions)])\n",
        "        \n",
        "        states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
        "        elite_states, elite_actions = strictly_select_elites(\n",
        "            states_batch, actions_batch, rewards_batch, percentile, classification)\n",
        "        \n",
        "        if classification:\n",
        "            agent.partial_fit(elite_states, elite_actions)\n",
        "        else:\n",
        "            elite_actions = elite_actions if (len(elite_actions.shape) < 2) or (elite_actions.shape[1] > 1)\\\n",
        "                            else elite_actions.reshape(-1)\n",
        "            agent.partial_fit(elite_states, elite_actions / agent_mul_fac)\n",
        "        \n",
        "        if verbose:\n",
        "            inter_min = np.min(rewards_batch)\n",
        "            min_lim = -n_game_steps if -n_game_steps < inter_min else inter_min\n",
        "            inter_max = np.max(rewards_batch)\n",
        "            max_lim = goal_score if goal_score > inter_max else inter_max\n",
        "            show_progress(rewards_batch, log, percentile, reward_range=[min_lim, max_lim])\n",
        "            \n",
        "            if np.mean(rewards_batch) > goal_score:\n",
        "                print(\"Вы выиграли! Можете прервать процедуру обучения с помощью сигнала KeyboardInterrupt.\")\n",
        "    \n",
        "    if verbose:\n",
        "        mean_reward = np.mean(rewards_batch)\n",
        "        threshold = np.percentile(rewards_batch, percentile)\n",
        "        print(\"средняя награда = %.3f, порог=%.3f\" % (mean_reward, threshold))\n",
        "        del mean_reward, threshold\n",
        "    \n",
        "    del env, sessions, states_batch, actions_batch, rewards_batch, elite_states, elite_actions\n",
        "    \n",
        "    return agent, log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQnd62OwYWHd"
      },
      "source": [
        "Функция для постановки экспериментов, зависящих от набора гиперпараметров:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5_sCRVrYWHd"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "\n",
        "\n",
        "def training_experiment(n_jobs_list, history_length_list, learning_rate_init_list, n_train_steps_list,\n",
        "                        n_samples=5, name='MountainCar-v0', n_game_steps=10000, n_sessions=100, percentile=70,\n",
        "                        goal_score=-150, **params):\n",
        "    experiment_data = []\n",
        "    \n",
        "    for n_jobs in n_jobs_list:\n",
        "        for history_length in history_length_list:\n",
        "            for learning_rate_init in learning_rate_init_list:\n",
        "                params['learning_rate_init'] = learning_rate_init\n",
        "                for n_train_steps in n_train_steps_list:\n",
        "                    elapsed_time_list = []\n",
        "                    log_list = []\n",
        "                    \n",
        "                    for i in range(n_samples):\n",
        "                        print(\n",
        "                            'Запуск: n_jobs = {}, history_length = {},\\n'.format(\n",
        "                                n_jobs, history_length) +\\\n",
        "                            '                  learning_rate_init = {}, n_train_steps = {};\\n'.format(\n",
        "                                learning_rate_init, n_train_steps) +\\\n",
        "                            'сэмпл {} из {}.'.format(\n",
        "                                i + 1, n_samples), flush=True)\n",
        "                        \n",
        "                        elapsed_time = time()\n",
        "                        \n",
        "                        agent, log = train_agent(\n",
        "                            classification=True, epsilon=0.01, name=name, n_train_steps=n_train_steps,\n",
        "                            n_game_steps=n_game_steps, n_sessions=n_sessions, percentile=percentile,\n",
        "                            goal_score=goal_score, history_length=history_length, n_jobs=n_jobs, verbose=True,\n",
        "                            **params)\n",
        "                        \n",
        "                        elapsed_time_list.append(time() - elapsed_time)\n",
        "                        \n",
        "                        log_list.append(log)\n",
        "                        \n",
        "                        del log, agent\n",
        "                        \n",
        "                    results = {\n",
        "                               'name': name,\n",
        "                               'goal_score': goal_score,\n",
        "                               'n_jobs': n_jobs,\n",
        "                               'elapsed_time_list': elapsed_time_list,\n",
        "                               'history_length': history_length,\n",
        "                               'learning_rate_init': learning_rate_init,\n",
        "                               'n_train_steps': n_train_steps,\n",
        "                               'log_list': log_list\n",
        "                              }\n",
        "                        \n",
        "                    experiment_data.append(results)\n",
        "                    \n",
        "                    del elapsed_time_list, log_list\n",
        "    return experiment_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSl5Bfg_YWHd"
      },
      "source": [
        "Функция-помощник для визуализации эффектов от переиспользования сэмплов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHj_cDXnYWHd"
      },
      "outputs": [],
      "source": [
        "def plot_history_length_experiment_results(df_data):\n",
        "    history_length_vals = []\n",
        "    train_step_vals = []\n",
        "    reward_vals = []\n",
        "    mean_threshold_vals = []\n",
        "    \n",
        "    for config in df_data:\n",
        "        for log in config['log_list']:\n",
        "            mean_rewards, reward_thresholds = zip(*log)\n",
        "            mean_rewards, reward_thresholds = list(mean_rewards), list(reward_thresholds)\n",
        "            reward_vals.extend(mean_rewards)\n",
        "            reward_vals.extend(reward_thresholds)\n",
        "            train_steps_num = len(mean_rewards)\n",
        "            train_step_vals.extend(range(train_steps_num))\n",
        "            train_step_vals.extend(range(train_steps_num))\n",
        "            history_length_vals.extend([config['history_length']] * train_steps_num * 2)\n",
        "            mean_threshold_vals.extend(['mean'] * train_steps_num)\n",
        "            mean_threshold_vals.extend(['threshold'] * train_steps_num)\n",
        "    \n",
        "    df = pd.DataFrame({'Переиспользованных шагов': history_length_vals, 'Шаг №': train_step_vals,\n",
        "                       'Награда': reward_vals, 'Вид награды': mean_threshold_vals})\n",
        "    last_steps_count = np.sort(df.loc[:, 'Переиспользованных шагов'].unique())\n",
        "    max_n_colors = last_steps_count.size\n",
        "    palette = dict(zip(last_steps_count, sns.hls_palette(max_n_colors, l=.45, s=.8)))\n",
        "    \n",
        "    sns.set(font_scale=1.35)\n",
        "    g = sns.relplot(x='Шаг №', y='Награда', hue='Переиспользованных шагов', style='Вид награды', kind='line',\n",
        "                    data=df, height=8, aspect=1.5, palette=palette)\n",
        "    g.fig.suptitle('Влияние количества переиспользованных шагов при обучении {}'.format(df_data[0]['name']))\n",
        "    clear_output(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZBGk_-_YWHe"
      },
      "source": [
        "Функция-помощник для визуализации влияния шага обучения и количества итераций при обучении агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJZ-LFXwYWHe"
      },
      "outputs": [],
      "source": [
        "def plot_lrt_experiment_results(df_data):\n",
        "    learning_rate_vals = []\n",
        "    max_train_steps_vals = []\n",
        "    train_step_vals = []\n",
        "    reward_vals = []\n",
        "    mean_threshold_vals = []\n",
        "    \n",
        "    for config in df_data:\n",
        "        for log in config['log_list']:\n",
        "            mean_rewards, reward_thresholds = zip(*log)\n",
        "            mean_rewards, reward_thresholds = list(mean_rewards), list(reward_thresholds)\n",
        "            reward_vals.extend(mean_rewards)\n",
        "            reward_vals.extend(reward_thresholds)\n",
        "            train_steps_num = len(mean_rewards)\n",
        "            train_step_vals.extend(range(train_steps_num))\n",
        "            train_step_vals.extend(range(train_steps_num))\n",
        "            learning_rate_vals.extend([config['learning_rate_init']] * train_steps_num * 2)\n",
        "            max_train_steps_vals.extend([config['n_train_steps']] * train_steps_num * 2)\n",
        "            mean_threshold_vals.extend(['mean'] * train_steps_num)\n",
        "            mean_threshold_vals.extend(['threshold'] * train_steps_num)\n",
        "                \n",
        "    df = pd.DataFrame({'Шаг метода': learning_rate_vals, 'Максимум шагов': max_train_steps_vals,\n",
        "                       'Шаг №': train_step_vals, 'Награда': reward_vals,\n",
        "                       'Вид награды': mean_threshold_vals})\n",
        "    lr_vals = np.sort(df.loc[:, 'Learning rate'].unique())\n",
        "    max_n_colors = lr_vals.size\n",
        "    palette = dict(zip(lr_vals, sns.hls_palette(max_n_colors, l=.45, s=.8)))\n",
        "    \n",
        "    sns.set(font_scale=1.35)\n",
        "    g = sns.relplot(x='Шаг №', y='Награда', hue='Шаг метода', style='Вид награды', kind='line',\n",
        "                    row='Максимум шагов', data=df, height=6, aspect=1.8, palette=palette)\n",
        "    g.fig.suptitle('Влияние шага метода и количества итераций на {}'.format(df_data[0]['name']),\n",
        "                   x=0.8, y=1.05)\n",
        "    leg = g._legend\n",
        "    for lr, label in zip(lr_vals, leg.texts[1:]):\n",
        "        label.set_text(\"{:.4f}\".format(lr))\n",
        "    clear_output(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7CKe0evYWHe"
      },
      "source": [
        "Функция для записи сэмплированных игровых эпизодов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtwLItt4YWHe"
      },
      "outputs": [],
      "source": [
        "def record_sessions(agent, name, t_max=10000, classification=True, epsilon=0.01, agent_mul_fac=1.0):\n",
        "    for kind, directory in [(True, \"test\"), (False, \"sample\")]:\n",
        "        env = gym.wrappers.Monitor(gym.make(name),\n",
        "                                   directory=\"videos/{}/{}\".format(name, directory), force=True)\n",
        "        sessions = [generate_parallel_session(agent, name=name, t_max=t_max, classification=classification,\n",
        "                                              epsilon=epsilon, agent_mul_fac=agent_mul_fac, test=kind,\n",
        "                                              env=env) for _ in range(100)]\n",
        "        env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VnYGrSTYWHe"
      },
      "source": [
        "Функция, позволяющая вставить запись игрового эпизода в ноутбук:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOkx0R8PYWHf"
      },
      "outputs": [],
      "source": [
        "def show_video(name, directory):\n",
        "    path = \"./videos/{}/{}\".format(name, directory)\n",
        "    video_names = list(\n",
        "        filter(lambda s: s.endswith(\".mp4\"), os.listdir(path)))\n",
        "    return HTML(\"\"\"\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"{}\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\".format(path + \"/\" + video_names[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9zF0MsWYWHf"
      },
      "source": [
        "Сетка параметров для проведения экспериментов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ULezxnKYWHf"
      },
      "outputs": [],
      "source": [
        "< n_jobs_list = сетка на количество процессов\n",
        "history_length_list = сетка на размер истории\n",
        "learning_rate_init_list = сетка на шаги метода\n",
        "n_train_steps_list = сетка на количество итераций метода >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyCVIM3YWHf"
      },
      "source": [
        "## Глубокий кросс-энтропийный метод в среде MountainCar-v0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T11:26:58.566980Z",
          "start_time": "2019-09-18T11:26:58.237111Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "TuVsmSLpYWHg"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.)\n",
        "env, n_actions, _ = get_env(\"MountainCar-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T11:26:59.458476Z",
          "start_time": "2019-09-18T11:26:59.453077Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "bgO4wubvYWHg"
      },
      "outputs": [],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ReVQm-TYWHg"
      },
      "source": [
        "Поиск оптимального количества параллельных легковесных процессов (нитей) на конечной машине:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtWxB_tcYWHg"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "n_jobs_experiment_data = < запуск перебора на сетке с помощью training_experiment >\n",
        "\n",
        "sns.set(font_scale=1.)\n",
        "pkl.dump(n_jobs_experiment_data, open('MountainCar-v0_n_jobs_experiment_data.pkl', 'wb'))\n",
        "clear_output(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjTnU-zhYWHg"
      },
      "source": [
        "Визуализация результатов эксперимента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ4wsn3SYWHg"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "n_jobs_vals = []\n",
        "elapsed_time_vals = []\n",
        "elapsed_time_vars = []\n",
        "\n",
        "for config in n_jobs_experiment_data:\n",
        "    n_jobs_vals.append(config['n_jobs'])\n",
        "    elapsed_time_vals.append(np.mean(config['elapsed_time_list']))\n",
        "    elapsed_time_vars.append(np.std(config['elapsed_time_list']))\n",
        "\n",
        "df = pd.DataFrame({'Количество нитей': n_jobs_vals, 'Средний ETA, сек.': elapsed_time_vals,\n",
        "                   'Стандартное отклонение ETA': elapsed_time_vars})\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.set(font_scale=1.35)\n",
        "plt.title('Производительность 5 итераций обучения на {}'.format(n_jobs_experiment_data[0]['name']),\n",
        "          fontsize=16)\n",
        "ax = sns.scatterplot(x='Количество нитей', y='Средний ETA, сек.', size='Стандартное отклонение ETA',\n",
        "                     sizes=(40, 400), data=df)\n",
        "min_val = np.min(elapsed_time_vals)\n",
        "ax.axhline(min_val, color='red', ls='--', linewidth=2, label='{:.2f} сек.'.format(min_val))\n",
        "plt.legend()\n",
        "clear_output(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvymWIGpYWHh"
      },
      "source": [
        "Исследование влияния переиспользования сэмплов в процессе обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eutDKEHYYWHh"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "history_length_experiment_data = < запуск перебора на сетке с помощью training_experiment >\n",
        "\n",
        "sns.set(font_scale=1.)\n",
        "pkl.dump(history_length_experiment_data, open('MountainCar-v0_history_length_experiment_data.pkl', 'wb'))\n",
        "clear_output(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw6Qo-zPYWHh"
      },
      "source": [
        "Результаты текущего эксперимента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJcw5YWWYWHh"
      },
      "outputs": [],
      "source": [
        "plot_history_length_experiment_results(history_length_experiment_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayINtGqtYWHh"
      },
      "source": [
        "Поиск оптимального шага обучения для многослойного перцептрона (MLP) вместе c подбором количества шагов обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXFKuSG8YWHh"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "lrt_experiment_data = < запуск перебора на сетке с помощью training_experiment >\n",
        "\n",
        "sns.set(font_scale=1.)\n",
        "pkl.dump(lrt_experiment_data, open('MountainCar-v0_lrt_experiment_data.pkl', 'wb'))\n",
        "clear_output(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r9TGKowYWHi"
      },
      "source": [
        "Результаты текущего эксперимента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU4mFU_5YWHi"
      },
      "outputs": [],
      "source": [
        "plot_lrt_experiment_results(lrt_experiment_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE_jXn-9YWHi"
      },
      "source": [
        "Обучение агента на задаче MountainCar-v0 с использованием подобранных ранее гиперпараметров:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlogrLRhYWHi"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "sns.set(font_scale=1.)\n",
        "agent, _ = < запуск функции train_agent для обучения агента >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td3PPjJ1YWHi"
      },
      "source": [
        "Визуализация действий обученного агента в зависимости скорости и положения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T11:55:31.581377Z",
          "start_time": "2019-09-18T11:55:31.311601Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "_8KCHhQ4YWHi"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.)\n",
        "plt.imshow(visualize_mountain_car(env, agent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPhfsrlyYWHi"
      },
      "source": [
        "Сэмпл детерминированной стратегии по въезду на холм:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0fzO-6CYWHi"
      },
      "outputs": [],
      "source": [
        "record_sessions(agent, \"MountainCar-v0\")\n",
        "show_video(\"MountainCar-v0\", \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F7WHOsPYWHj"
      },
      "source": [
        "Сэмпл стохастической стратегии по въезду на холм:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSDXEfbtYWHj"
      },
      "outputs": [],
      "source": [
        "show_video(\"MountainCar-v0\", \"sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoXK4GKeYWHj"
      },
      "source": [
        "## Обучение агента в среде LunarLander-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-18T12:12:40.985701Z",
          "start_time": "2019-09-18T12:12:40.844112Z"
        },
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "NZEcBSthYWHj"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.)\n",
        "env, n_actions, _ = get_env(\"LunarLander-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-tzMF7TYWHj"
      },
      "outputs": [],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHoq5PVnYWHj"
      },
      "source": [
        "Обучение агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv2bRBhvYWHj"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "agent, _ = < запуск функции train_agent для обучения агента >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hliIHFQxYWHk"
      },
      "source": [
        "Детерминированная стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0aY9BvxYWHk"
      },
      "outputs": [],
      "source": [
        "record_sessions(agent, 'LunarLander-v2', t_max=1000)\n",
        "show_video('LunarLander-v2', 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVJ-kAXGYWHk"
      },
      "source": [
        "Стохастическая стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndXzQVtFYWHk"
      },
      "outputs": [],
      "source": [
        "show_video('LunarLander-v2', 'sample')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "cKhgGSvJYWHk"
      },
      "source": [
        "### Ещё дополнительное задание (вплоть до 5 баллов)\n",
        "\n",
        "* __2.3 дополнительное__ Обучить агента в среде с непрерывным пространством действий с помощью `MLPRegressor` или похожим образом.\n",
        "  * Начните с [\"Pendulum-v0\"](https://www.gymlibrary.dev/environments/classic_control/pendulum/), попробуйте получить среднее вознаграждение **как минимум -300**.\n",
        "  * Поскольку Ваш агент оценивает \"среднее\" действие, полезно добавить небольшой шум для исследования среды.\n",
        "  * Обучить агентов в [MountainCarContinuous-v0](https://mgoulao.github.io/gym-docs/environments/classic_control/mountain_car_continuous/), [LunarLanderContinuous-v2](https://www.gymlibrary.dev/environments/box2d/lunar_lander/). За достижение награды ниже порогового значения будет начислено меньше баллов. Помните, что дискретные и непрерывные среды могут отличаться не только в пространстве действий. Требования на среднее вознаграждение такие же, как и в случае сред **MountainCar** и **LunarLander** ранее.\n",
        "  * __Просьба при сдаче задания перечислить, что было сделано__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2uzY99RYWHk"
      },
      "source": [
        "## Обучение в Pendulum-v0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw780SpTYWHl"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.)\n",
        "env, n_actions, _ = get_env('Pendulum-v0', False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcAwL8MLYWHl"
      },
      "outputs": [],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkVdV3RBYWHl"
      },
      "source": [
        "Обучение агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6vHqUzjYWHl"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "agent, _ = < запуск функции train_agent для обучения агента >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ingjq_TYWHl"
      },
      "source": [
        "Детерминированная стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPHTVzIcYWHl"
      },
      "outputs": [],
      "source": [
        "record_sessions(agent, 'Pendulum-v0', t_max=1000, classification=False, epsilon=.5, agent_mul_fac=2.)\n",
        "show_video('Pendulum-v0', 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNALmXGWYWHm"
      },
      "source": [
        "Стохастическая стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZKJF_g-YWHm"
      },
      "outputs": [],
      "source": [
        "show_video('Pendulum-v0', 'sample')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEspdMUcYWHm"
      },
      "source": [
        "## Обучение MountainCarContinuous-v0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35lL82LIYWHm"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.)\n",
        "env, n_actions, _ = get_env('MountainCarContinuous-v0', False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_lJfJlAYWHm"
      },
      "outputs": [],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoWadueFYWHm"
      },
      "source": [
        "Обучение агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgIwtjHYYWHm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "agent, _ = < запуск функции train_agent для обучения агента >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwoh22ivYWHm"
      },
      "source": [
        "Детерминированная стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBq8RkE3YWHn"
      },
      "outputs": [],
      "source": [
        "record_sessions(agent, 'MountainCarContinuous-v0', t_max=10000, classification=False, epsilon=1.0,\n",
        "                agent_mul_fac=1.0)\n",
        "show_video('MountainCarContinuous-v0', 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBnTeyK_YWHn"
      },
      "source": [
        "Стохастическая стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifpQ77e0YWHn"
      },
      "outputs": [],
      "source": [
        "show_video('MountainCarContinuous-v0', 'sample')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzO_gKszYWHn"
      },
      "source": [
        "## Обучение LunarLanderContinuous-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltfF1KLOYWHn"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.)\n",
        "env, n_actions, _ = get_env('LunarLanderContinuous-v2', False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOOGmr-BYWHn"
      },
      "outputs": [],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjEa_N_SYWHn"
      },
      "source": [
        "Обучение агента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLB5l56QYWHo"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "agent, _ = < запуск функции train_agent для обучения агента >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2CpfL79YWHo"
      },
      "source": [
        "Детерминированная стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypC-Fp7LYWHo"
      },
      "outputs": [],
      "source": [
        "record_sessions(agent, 'LunarLanderContinuous-v2', t_max=1000, classification=False, epsilon=1.0,\n",
        "                agent_mul_fac=1.0)\n",
        "show_video('LunarLanderContinuous-v2', 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csg6eMRrYWHo"
      },
      "source": [
        "Стохастическая стратегия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snddY5fKYWHo"
      },
      "outputs": [],
      "source": [
        "show_video('LunarLanderContinuous-v2', 'sample')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3_jf7oTYWHo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}